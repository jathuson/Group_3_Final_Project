{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b570c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af17ed",
   "metadata": {},
   "source": [
    "### Links table cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c614cce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 62423\n",
      "   movieId  imdbId   tmdbId\n",
      "0        1  114709    862.0\n",
      "1        2  113497   8844.0\n",
      "2        3  113228  15602.0\n",
      "3        4  114885  31357.0\n",
      "4        5  113041  11862.0\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "raw_links_df = pd.read_csv(\"../raw_data_tables/raw_links.csv\")\n",
    "print(f'number of records: {len(raw_links_df)}')\n",
    "print(raw_links_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0839e111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['movieId', 0], ['imdbId', 0], ['tmdbId', 107]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values \n",
    "[[column,raw_links_df[column].isnull().sum()] for column in raw_links_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946e8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#null tmbdID's are acceptable in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d42d877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId      int64\n",
       "imdbId       int64\n",
       "tmdbId     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types\n",
    "raw_links_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be2f95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId    int64\n",
       "imdbId     int64\n",
       "tmdbId     int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert tmdbId to int type and fill NaN's with 0\n",
    "raw_links_df['tmdbId'] = raw_links_df['tmdbId'].fillna(0).astype(int)\n",
    "raw_links_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e88abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 62423\n",
      "   movieId  imdbId  tmdbId\n",
      "0        1  114709     862\n",
      "1        2  113497    8844\n",
      "2        3  113228   15602\n",
      "3        4  114885   31357\n",
      "4        5  113041   11862\n",
      "movieId    int64\n",
      "imdbId     int64\n",
      "tmdbId     int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#create clean df and confirm \n",
    "clean_links_df = raw_links_df\n",
    "print(f'number of records: {len(clean_links_df)}')\n",
    "print(clean_links_df.head())\n",
    "print(clean_links_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baba026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean csv for import into Postgres \n",
    "clean_links_df.to_csv('../clean_data_tables/clean_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62433d5d",
   "metadata": {},
   "source": [
    "### Tags table cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b665bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 1093360\n",
      "   userId  movieId               tag   timestamp\n",
      "0       3      260           classic  1439472355\n",
      "1       3      260            sci-fi  1439472256\n",
      "2       4     1732       dark comedy  1573943598\n",
      "3       4     1732    great dialogue  1573943604\n",
      "4       4     7569  so bad it's good  1573943455\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "raw_tags_df = pd.read_csv(\"../raw_data_tables/raw_tags.csv\")\n",
    "print(f'number of records: {len(raw_tags_df)}')\n",
    "print(raw_tags_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6dda02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['userId', 0], ['movieId', 0], ['tag', 16], ['timestamp', 0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values \n",
    "[[column,raw_tags_df[column].isnull().sum()] for column in raw_tags_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90d5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#null tags are acceptable in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c082e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>classic</td>\n",
       "      <td>2015-08-13 13:25:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>sci-fi</td>\n",
       "      <td>2015-08-13 13:24:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1732</td>\n",
       "      <td>dark comedy</td>\n",
       "      <td>2019-11-16 22:33:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1732</td>\n",
       "      <td>great dialogue</td>\n",
       "      <td>2019-11-16 22:33:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7569</td>\n",
       "      <td>so bad it's good</td>\n",
       "      <td>2019-11-16 22:30:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId               tag           timestamp\n",
       "0       3      260           classic 2015-08-13 13:25:55\n",
       "1       3      260            sci-fi 2015-08-13 13:24:16\n",
       "2       4     1732       dark comedy 2019-11-16 22:33:18\n",
       "3       4     1732    great dialogue 2019-11-16 22:33:24\n",
       "4       4     7569  so bad it's good 2019-11-16 22:30:55"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert Unix timestap to standard format\n",
    "raw_tags_df['timestamp'] = pd.to_datetime(raw_tags_df['timestamp'], unit='s')\n",
    "raw_tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf346446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId                int64\n",
       "movieId               int64\n",
       "tag                  object\n",
       "timestamp    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types\n",
    "raw_tags_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac3af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 1093360\n",
      "   userId  movieId               tag           timestamp\n",
      "0       3      260           classic 2015-08-13 13:25:55\n",
      "1       3      260            sci-fi 2015-08-13 13:24:16\n",
      "2       4     1732       dark comedy 2019-11-16 22:33:18\n",
      "3       4     1732    great dialogue 2019-11-16 22:33:24\n",
      "4       4     7569  so bad it's good 2019-11-16 22:30:55\n",
      "userId                int64\n",
      "movieId               int64\n",
      "tag                  object\n",
      "timestamp    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#create clean df and confirm \n",
    "clean_tags_df = raw_tags_df\n",
    "print(f'number of records: {len(clean_tags_df)}')\n",
    "print(clean_tags_df.head())\n",
    "print(clean_tags_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2d200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean csv for import into Postgres \n",
    "clean_tags_df.to_csv('../clean_data_tables/clean_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2bb51",
   "metadata": {},
   "source": [
    "### Movies table cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06fd95fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 62423\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "raw_movies_df = pd.read_csv(\"../raw_data_tables/raw_movies.csv\")\n",
    "print(f'number of records: {len(raw_movies_df)}')\n",
    "print(raw_movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eabb7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['movieId', 0], ['title', 0], ['genres', 0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values \n",
    "[[column,raw_movies_df[column].isnull().sum()] for column in raw_movies_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2dd4b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Byron\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Byron\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Byron\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  \"\"\"\n",
      "C:\\Users\\Byron\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Adventure, Animation, Children, Comedy, Fantasy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Adventure, Children, Fantasy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                         title  \\\n",
       "0        1                    Toy Story    \n",
       "1        2                      Jumanji    \n",
       "2        3             Grumpier Old Men    \n",
       "3        4            Waiting to Exhale    \n",
       "4        5  Father of the Bride Part II    \n",
       "\n",
       "                                            genres  year  \n",
       "0  Adventure, Animation, Children, Comedy, Fantasy  1995  \n",
       "1                     Adventure, Children, Fantasy  1995  \n",
       "2                                  Comedy, Romance  1995  \n",
       "3                           Comedy, Drama, Romance  1995  \n",
       "4                                           Comedy  1995  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split year from title into separate column and format stings in columns\n",
    "raw_movies_df['year'] = raw_movies_df['title'].str.extract(r'(\\(\\d{4}\\))')\n",
    "raw_movies_df['title'] = raw_movies_df['title'].str.replace(r'(\\(\\d{4}\\))',\"\")\n",
    "raw_movies_df['year'] = raw_movies_df['year'].str.replace('(',\"\")\n",
    "raw_movies_df['year'] = raw_movies_df['year'].str.replace(')',\"\")\n",
    "raw_movies_df['genres'] = raw_movies_df['genres'].str.replace('|',\", \")\n",
    "raw_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa6c8663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['movieId', 0], ['title', 0], ['genres', 0], ['year', 410]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recheck for null values \n",
    "[[column,raw_movies_df[column].isnull().sum()] for column in raw_movies_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54867057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId     int64\n",
       "title      object\n",
       "genres     object\n",
       "year       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types\n",
    "raw_movies_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "420de1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert year to int type and fill NaN's with 0\n",
    "raw_movies_df['year'] = raw_movies_df['year'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f1091ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId     int64\n",
       "title      object\n",
       "genres     object\n",
       "year        int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types\n",
    "raw_movies_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4db3cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 62423\n",
      "   movieId                         title  \\\n",
      "0        1                    Toy Story    \n",
      "1        2                      Jumanji    \n",
      "2        3             Grumpier Old Men    \n",
      "3        4            Waiting to Exhale    \n",
      "4        5  Father of the Bride Part II    \n",
      "\n",
      "                                            genres  year  \n",
      "0  Adventure, Animation, Children, Comedy, Fantasy  1995  \n",
      "1                     Adventure, Children, Fantasy  1995  \n",
      "2                                  Comedy, Romance  1995  \n",
      "3                           Comedy, Drama, Romance  1995  \n",
      "4                                           Comedy  1995  \n",
      "movieId     int64\n",
      "title      object\n",
      "genres     object\n",
      "year        int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#create clean df and confirm \n",
    "clean_movies_df = raw_movies_df\n",
    "print(f'number of records: {len(clean_movies_df)}')\n",
    "print(clean_movies_df.head())\n",
    "print(clean_movies_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cd50805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean csv for import into Postgres \n",
    "clean_movies_df.to_csv('../clean_data_tables/clean_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233b3ed",
   "metadata": {},
   "source": [
    "### Ratings table cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e78bee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 25000095\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "raw_ratings_df = pd.read_csv(\"../raw_data_tables/raw_ratings.csv\")\n",
    "print(f'number of records: {len(raw_ratings_df)}')\n",
    "print(raw_ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01b5f665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['userId', 0], ['movieId', 0], ['rating', 0], ['timestamp', 0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values \n",
    "[[column,raw_ratings_df[column].isnull().sum()] for column in raw_ratings_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae3e75ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2006-05-17 15:34:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2006-05-17 12:26:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2006-05-17 12:27:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2006-05-17 15:13:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2006-05-17 12:21:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating           timestamp\n",
       "0       1      296     5.0 2006-05-17 15:34:04\n",
       "1       1      306     3.5 2006-05-17 12:26:57\n",
       "2       1      307     5.0 2006-05-17 12:27:08\n",
       "3       1      665     5.0 2006-05-17 15:13:40\n",
       "4       1      899     3.5 2006-05-17 12:21:50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert Unix timestap to standard format\n",
    "raw_ratings_df['timestamp'] = pd.to_datetime(raw_ratings_df['timestamp'], unit='s')\n",
    "raw_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1262dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId                int64\n",
       "movieId               int64\n",
       "rating              float64\n",
       "timestamp    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types\n",
    "raw_ratings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2babaa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 25000095\n",
      "   userId  movieId  rating           timestamp\n",
      "0       1      296     5.0 2006-05-17 15:34:04\n",
      "1       1      306     3.5 2006-05-17 12:26:57\n",
      "2       1      307     5.0 2006-05-17 12:27:08\n",
      "3       1      665     5.0 2006-05-17 15:13:40\n",
      "4       1      899     3.5 2006-05-17 12:21:50\n",
      "userId                int64\n",
      "movieId               int64\n",
      "rating              float64\n",
      "timestamp    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#create clean df and confirm \n",
    "clean_ratings_df = raw_ratings_df\n",
    "print(f'number of records: {len(clean_ratings_df)}')\n",
    "print(clean_ratings_df.head())\n",
    "print(clean_ratings_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f04228ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean csv for import into Postgres \n",
    "clean_ratings_df.to_csv('../clean_data_tables/clean_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de0d02d",
   "metadata": {},
   "source": [
    "### Genome Scores table cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "478c354e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 15584448\n",
      "   movieId  tagId  relevance\n",
      "0        1      1    0.02875\n",
      "1        1      2    0.02375\n",
      "2        1      3    0.06250\n",
      "3        1      4    0.07575\n",
      "4        1      5    0.14075\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "raw_genome_scores_df = pd.read_csv(\"../raw_data_tables/raw_genome_scores.csv\")\n",
    "print(f'number of records: {len(raw_genome_scores_df)}')\n",
    "print(raw_genome_scores_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0785c46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['movieId', 0], ['tagId', 0], ['relevance', 0]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values \n",
    "[[column,raw_genome_scores_df[column].isnull().sum()] for column in raw_genome_scores_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ef7569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId        int64\n",
       "tagId          int64\n",
       "relevance    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types\n",
    "raw_genome_scores_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd5095d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 15584448\n",
      "   movieId  tagId  relevance\n",
      "0        1      1    0.02875\n",
      "1        1      2    0.02375\n",
      "2        1      3    0.06250\n",
      "3        1      4    0.07575\n",
      "4        1      5    0.14075\n",
      "movieId        int64\n",
      "tagId          int64\n",
      "relevance    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#create clean df and confirm \n",
    "clean_genome_scores_df = raw_genome_scores_df\n",
    "print(f'number of records: {len(clean_genome_scores_df)}')\n",
    "print(clean_genome_scores_df.head())\n",
    "print(clean_genome_scores_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "267973a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean csv for import into Postgres \n",
    "clean_genome_scores_df.to_csv('../clean_data_tables/clean_genome_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9689af64",
   "metadata": {},
   "source": [
    "### Genome Tags table cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68981c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 1128\n",
      "   tagId           tag\n",
      "0      1           007\n",
      "1      2  007 (series)\n",
      "2      3  18th century\n",
      "3      4         1920s\n",
      "4      5         1930s\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "raw_genome_tags_df = pd.read_csv(\"../raw_data_tables/raw_genome_tags.csv\")\n",
    "print(f'number of records: {len(raw_genome_tags_df)}')\n",
    "print(raw_genome_tags_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35107edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tagId', 0], ['tag', 0]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values \n",
    "[[column,raw_genome_tags_df[column].isnull().sum()] for column in raw_genome_tags_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d58887f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tagId     int64\n",
       "tag      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types\n",
    "raw_genome_tags_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c30ab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records: 1128\n",
      "   tagId           tag\n",
      "0      1           007\n",
      "1      2  007 (series)\n",
      "2      3  18th century\n",
      "3      4         1920s\n",
      "4      5         1930s\n",
      "tagId     int64\n",
      "tag      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#create clean df and confirm \n",
    "clean_genome_tags_df = raw_genome_tags_df\n",
    "print(f'number of records: {len(clean_genome_tags_df)}')\n",
    "print(clean_genome_tags_df.head())\n",
    "print(clean_genome_tags_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df916dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export clean csv for import into Postgres \n",
    "clean_genome_tags_df.to_csv('../clean_data_tables/clean_genome_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e619f55a",
   "metadata": {},
   "source": [
    "### Load cleaned tables to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e23b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db connectoin string\n",
    "db_string = f\"postgresql://root:{db_password}@bootcamp-group-3.cn5djhczpkaa.us-east-1.rds.amazonaws.com:5432/Bootcamp_Group_3\"\n",
    "\n",
    "#create db engine\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "852b4160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 62423...Done. 4.733666181564331 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "#load Links table into SQL\n",
    "\n",
    "# chunk csv data, print rows being exported, run timer\n",
    "rows_imported = 0\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv('../clean_data_tables/clean_links.csv', chunksize=1000000):\n",
    "\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')  \n",
    "    data.to_sql(name='Links', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "    \n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8f5a563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1000000...Done. 73.06456446647644 total seconds elapsed\n",
      "importing rows 1000000 to 1093360...Done. 79.7902421951294 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "#load Tags table into SQL\n",
    "\n",
    "# chunk csv data, print rows being exported, run timer\n",
    "rows_imported = 0\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv('../clean_data_tables/clean_tags.csv', chunksize=1000000):\n",
    "\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')  \n",
    "    data.to_sql(name='Tags', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "    \n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e57ef468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 62423...Done. 4.9317097663879395 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "#load Movies table into SQL\n",
    "\n",
    "# chunk csv data, print rows being exported, run timer\n",
    "rows_imported = 0\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv('../clean_data_tables/clean_movies.csv', chunksize=1000000):\n",
    "\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')  \n",
    "    data.to_sql(name='Movies', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "    \n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "deecbb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1000000...Done. 71.15868973731995 total seconds elapsed\n",
      "importing rows 1000000 to 2000000...Done. 141.15570187568665 total seconds elapsed\n",
      "importing rows 2000000 to 3000000...Done. 210.76349782943726 total seconds elapsed\n",
      "importing rows 3000000 to 4000000...Done. 280.3184494972229 total seconds elapsed\n",
      "importing rows 4000000 to 5000000...Done. 350.010888338089 total seconds elapsed\n",
      "importing rows 5000000 to 6000000...Done. 419.220801115036 total seconds elapsed\n",
      "importing rows 6000000 to 7000000...Done. 490.9897210597992 total seconds elapsed\n",
      "importing rows 7000000 to 8000000...Done. 562.0016000270844 total seconds elapsed\n",
      "importing rows 8000000 to 9000000...Done. 632.2053627967834 total seconds elapsed\n",
      "importing rows 9000000 to 10000000...Done. 702.3810873031616 total seconds elapsed\n",
      "importing rows 10000000 to 11000000...Done. 772.4283475875854 total seconds elapsed\n",
      "importing rows 11000000 to 12000000...Done. 842.6532368659973 total seconds elapsed\n",
      "importing rows 12000000 to 13000000...Done. 913.1119267940521 total seconds elapsed\n",
      "importing rows 13000000 to 14000000...Done. 983.0988342761993 total seconds elapsed\n",
      "importing rows 14000000 to 15000000...Done. 1052.9971947669983 total seconds elapsed\n",
      "importing rows 15000000 to 16000000...Done. 1123.4620263576508 total seconds elapsed\n",
      "importing rows 16000000 to 17000000...Done. 1193.9051792621613 total seconds elapsed\n",
      "importing rows 17000000 to 18000000...Done. 1264.90580701828 total seconds elapsed\n",
      "importing rows 18000000 to 19000000...Done. 1334.9866707324982 total seconds elapsed\n",
      "importing rows 19000000 to 20000000...Done. 1405.2801492214203 total seconds elapsed\n",
      "importing rows 20000000 to 21000000...Done. 1475.7842259407043 total seconds elapsed\n",
      "importing rows 21000000 to 22000000...Done. 1545.9245631694794 total seconds elapsed\n",
      "importing rows 22000000 to 23000000...Done. 1618.5610880851746 total seconds elapsed\n",
      "importing rows 23000000 to 24000000...Done. 1688.1749403476715 total seconds elapsed\n",
      "importing rows 24000000 to 25000000...Done. 1761.1713857650757 total seconds elapsed\n",
      "importing rows 25000000 to 25000095...Done. 1761.5884048938751 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "#load Ratings table into SQL\n",
    "\n",
    "# chunk csv data, print rows being exported, run timer\n",
    "rows_imported = 0\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv('../clean_data_tables/clean_ratings.csv', chunksize=1000000):\n",
    "\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')  \n",
    "    data.to_sql(name='Ratings', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "    \n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f117847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1000000...Done. 63.15814685821533 total seconds elapsed\n",
      "importing rows 1000000 to 2000000...Done. 126.12455129623413 total seconds elapsed\n",
      "importing rows 2000000 to 3000000...Done. 189.05762577056885 total seconds elapsed\n",
      "importing rows 3000000 to 4000000...Done. 255.23566341400146 total seconds elapsed\n",
      "importing rows 4000000 to 5000000...Done. 321.57755756378174 total seconds elapsed\n",
      "importing rows 5000000 to 6000000...Done. 384.7476463317871 total seconds elapsed\n",
      "importing rows 6000000 to 7000000...Done. 449.8145673274994 total seconds elapsed\n",
      "importing rows 7000000 to 8000000...Done. 512.6436941623688 total seconds elapsed\n",
      "importing rows 8000000 to 9000000...Done. 577.7558212280273 total seconds elapsed\n",
      "importing rows 9000000 to 10000000...Done. 641.1769278049469 total seconds elapsed\n",
      "importing rows 10000000 to 11000000...Done. 704.5450882911682 total seconds elapsed\n",
      "importing rows 11000000 to 12000000...Done. 768.5639190673828 total seconds elapsed\n",
      "importing rows 12000000 to 13000000...Done. 831.6432020664215 total seconds elapsed\n",
      "importing rows 13000000 to 14000000...Done. 895.0558063983917 total seconds elapsed\n",
      "importing rows 14000000 to 15000000...Done. 957.6715495586395 total seconds elapsed\n",
      "importing rows 15000000 to 15584448...Done. 995.0989620685577 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "#load Genome Scores table into SQL\n",
    "\n",
    "# chunk csv data, print rows being exported, run timer\n",
    "rows_imported = 0\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv('../clean_data_tables/clean_genome_scores.csv', chunksize=1000000):\n",
    "\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')  \n",
    "    data.to_sql(name='Genome_Scores', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "    \n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "edc0c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1128...Done. 0.5556180477142334 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "#load Genome Tags table into SQL\n",
    "\n",
    "# chunk csv data, print rows being exported, run timer\n",
    "rows_imported = 0\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv('../clean_data_tables/clean_genome_tags.csv', chunksize=1000000):\n",
    "\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')  \n",
    "    data.to_sql(name='Genome_Tags', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "    \n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
